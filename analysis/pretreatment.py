import pandas as pd
import emoji
import re
from sklearn.preprocessing import MinMaxScaler


df = pd.read_csv("twitter-posts.csv")

# D√©finir un seuil pour les valeurs manquantes
threshold = 800

# Supprimer les colonnes o√π le nombre de valeurs manquantes est sup√©rieur au seuil
df_cleaned = df.loc[:, df.isnull().sum() <= threshold]

# V√©rifier les valeurs manquantes apr√®s suppression
missing_after_deletion = df_cleaned.isnull().sum()
print("\nValeurs manquantes apr√®s suppression des colonnes avec plus de 900 valeurs manquantes:")
print(missing_after_deletion)

# V√©rifier un √©chantillon des donn√©es apr√®s suppression des colonnes
print("\nExemple de donn√©es apr√®s suppression:")
print(df_cleaned.head())

# √âtape 1: Remplir les valeurs manquantes pour la colonne 'followers' avec 0
df['followers'] = df['followers'].fillna(0)

# √âtape 2: Remplir les valeurs manquantes pour 'likes' avec la valeur la plus fr√©quente (mode)
# Assurez-vous d'abord que la colonne 'likes' est bien num√©rique
df['likes'] = pd.to_numeric(df['likes'], errors='coerce')  # Convertir en num√©rique, en cas d'erreur remplacer par NaN
df['likes'] = df['likes'].fillna(df['likes'].mode()[0])  # Remplacer les NaN par la valeur la plus fr√©quente

# √âtape 3: Remplir les valeurs manquantes pour 'description' avec 'Non sp√©cifi√©'
df['description'] = df['description'].fillna('Non sp√©cifi√©')

# Remplir les valeurs manquantes dans 'photos', 'videos', et 'hashtags' par des listes vides
df['photos'] = df['photos'].fillna('[]')  # Utiliser des cha√Ænes vides ou des listes vides, selon le format
df['videos'] = df['videos'].fillna('[]')
df['hashtags'] = df['hashtags'].fillna('[]')

# Si n√©cessaire, vous pouvez √©galement convertir ces cha√Ænes en listes
# Exemple pour convertir une cha√Æne de caract√®res en liste
import ast
df['photos'] = df['photos'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])
df['videos'] = df['videos'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])
df['hashtags'] = df['hashtags'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])

# Remplir les valeurs manquantes dans 'biography' et 'external_url'
df['biography'] = df['biography'].fillna('Non sp√©cifi√©')
df['external_url'] = df['external_url'].fillna('Non disponible')

# Remplir les valeurs manquantes dans 'tagged_users' par une liste vide ou une cha√Æne par d√©faut
df['tagged_users'] = df['tagged_users'].fillna('Non sp√©cifi√©')

# Remplir les valeurs manquantes dans 'views' par la moyenne ou la m√©diane (en fonction de la distribution)
df['views'] = df['views'].fillna(df['views'].median())  # Utilisation de la m√©diane pour √©viter les valeurs extr√™mes

# V√©rifier si des valeurs manquantes existent encore
missing_values = df.isnull().sum()
print("\nValeurs manquantes apr√®s remplissage:")
print(missing_values)

# Supprimer les doublons bas√©s sur l'ID du tweet
df.drop_duplicates(subset='id', keep='last', inplace=True)

# Convert 'date_posted' to datetime with a specified format
df['date_posted'] = pd.to_datetime(df['date_posted'], format="%Y-%m-%d", errors='coerce')

# Convert numeric columns
df['followers'] = pd.to_numeric(df['followers'], errors='coerce')
df['likes'] = pd.to_numeric(df['likes'], errors='coerce')
df['reposts'] = pd.to_numeric(df['reposts'], errors='coerce')

import re

# Fonction pour nettoyer les textes des tweets


# Dictionnaire d'√©mojis avec sentiments associ√©s
emoji_sentiment_dict = {
    'üòÄ': 'positif', 'üòä': 'positif', 'üòç': 'positif', 'üòé': 'positif',
    'üò¢': 'n√©gatif', 'üòû': 'n√©gatif', 'üò°': 'n√©gatif', 'üò≠': 'n√©gatif',
    'üò±': 'n√©gatif', 'üôÅ': 'n√©gatif', 'üòî': 'n√©gatif',
    'üòÉ': 'positif', 'üòÖ': 'positif', 'üòú': 'positif',
    'üí•': 'n√©gatif', 'üî•': 'n√©gatif'
    # Ajoutez plus d'√©mojis et de sentiments si n√©cessaire
}


def clean_text(text):
    if not isinstance(text, str):
        return ""
    

    # Enlever les URLs, mentions, hashtags et caract√®res sp√©ciaux
    text = re.sub(r"http\S+|www\S+|https\S+", "", text)  # Supprimer les URLs
    text = re.sub(r"@\w+", "", text)  # Supprimer les mentions (@)
    text = re.sub(r"#\w+", "", text)  # Supprimer les hashtags 
    # Retirer les espaces suppl√©mentaires
    text = re.sub(r'\s+', ' ', text).strip()  
    # Supprimer la ponctuation excessive (r√©p√©t√©e 2 fois ou plus)
    text = re.sub(r'([!?.])\1+', r'\1', text)  # Ex: "!!!!" -> "!"


    return text.lower()  # Convertir le texte en minuscule pour l'analyse de sentiment
# Fonction pour extraire et associer les √©mojis √† des sentiments
def extract_emoji_sentiment(text):
    emojis_in_text = emoji.emoji_list(text)  # Liste d'√©mojis pr√©sents dans le texte
    sentiments = []
    
    for emj in emojis_in_text:
        emj_char = emj['emoji']  # R√©cup√©rer l'√©moji
        if emj_char in emoji_sentiment_dict:
            sentiments.append(emoji_sentiment_dict[emj_char])
    
    return sentiments

# Appliquer le nettoyage directement sur la colonne 'description'
df[ 'cleaned_description'] = df['description'].apply(lambda x:clean_text(str(x)))

# Extraire les sentiments associ√©s aux √©mojis et les associer au texte nettoy√©
df[ 'cleaned_description'] = df[ 'cleaned_description'].apply(lambda x: ' '.join(extract_emoji_sentiment(x)) + ' ' + x)

# V√©rifier un √©chantillon des donn√©es nettoy√©es
print("\nExemple de donn√©es nettoy√©es:")
print(df[['description', 'cleaned_description']].head())



# Extraire des caract√©ristiques temporelles comme l'heure de publication et le jour de la semaine
df['hour'] = df['date_posted'].dt.hour
df['day_of_week'] = df['date_posted'].dt.day_name()

# Cr√©er un score d'engagement global (en fonction des interactions)
df['engagement_score'] = (2 * df['reposts']) + df['likes'] + df['replies'] + df['quotes'] + df['bookmarks']

# Calculer le taux d'engagement (score d'engagement par rapport au nombre de followers)
df['engagement_rate'] = df['engagement_score'] / (df['followers'] + 1)  # Eviter la division par z√©ro

# Calculer le score de viralit√© (engagement par rapport aux vues)
df['virality_score'] = df['engagement_score'] / (df['views'] + 1)


# D√©tection des outliers pour les colonnes de likes et followers
Q1 = df['likes'].quantile(0.25)
Q3 = df['likes'].quantile(0.75)
IQR = Q3 - Q1
df = df[(df['likes'] >= (Q1 - 1.5 * IQR)) & (df['likes'] <= (Q3 + 1.5 * IQR))]

# Filtrer les outliers pour les followers
Q1_followers = df['followers'].quantile(0.25)
Q3_followers = df['followers'].quantile(0.75)
IQR_followers = Q3_followers - Q1_followers
df = df[(df['followers'] >= (Q1_followers - 1.5 * IQR_followers)) & (df['followers'] <= (Q3_followers + 1.5 * IQR_followers))]

# Compute new engagement-based features (e.g., engagement score)
df['engagement_score'] = (2 * df['reposts']) + df['likes'] + df['replies'] + df['quotes'] + df['bookmarks']
df['engagement_rate'] = df['engagement_score'] / (df['followers'] + 1)
df['virality_score'] = df['engagement_score'] / (df['views'] + 1)


# Extract day of the week and hour of the day
df['hour'] = df['date_posted'].dt.hour
df['day_of_week'] = df['date_posted'].dt.day_name()

# Cr√©er des m√©triques suppl√©mentaires comme le nombre de hashtags
df['num_hashtags'] = df['hashtags'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)

# Engendrer un score de popularit√© bas√© sur le nombre de likes, reposts et replies
df['popularity_score'] = df['likes'] + 2 * df['reposts'] + 1.5 * df['replies']
df.to_csv("twitter_cleaned.csv", index=False)  # Sauvegarde en CSV
